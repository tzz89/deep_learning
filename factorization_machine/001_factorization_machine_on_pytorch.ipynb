{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357ce10f-4f5c-4912-8909-1f609b17947c",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. https://medium.com/@datadote/factorization-machines-pictures-code-pytorch-9fca1c300838"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e28dd-827e-4f3d-be65-79eb29f4b042",
   "metadata": {},
   "source": [
    "## Getting the dataset and unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0e3c3f-d806-4a03-8201-e7fb1f93f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-09 20:19:45--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: ‘../datasets/factorization_machine/ml-1m.zip’\n",
      "\n",
      "ml-1m.zip           100%[===================>]   5.64M  2.26MB/s    in 2.5s    \n",
      "\n",
      "2024-08-09 20:19:49 (2.26 MB/s) - ‘../datasets/factorization_machine/ml-1m.zip’ saved [5917549/5917549]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip -P ../datasets/factorization_machine/\n",
    "!unzip ../datasets/factorization_machine/ml-1m.zip -d ../datasets/factorization_machine/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f86ad2-4f95-4d6c-bbf7-df60d264e888",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d45c930-940c-4239-a201-835edc77ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ad15a-c3fc-464b-a4bb-a5ea013dfe1f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e2eb0-6476-4a9c-823b-9088364728e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661dd4d2-7cff-4812-b6c5-efb38bfb706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "      <td>Girl, Interrupted (1999)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Comedy|Sci-Fi</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>978300055</td>\n",
       "      <td>Titanic (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>978300055</td>\n",
       "      <td>Cinderella (1950)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>978300103</td>\n",
       "      <td>Meet Joe Black (1998)</td>\n",
       "      <td>Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>997454429</td>\n",
       "      <td>Body Heat (1981)</td>\n",
       "      <td>Crime|Thriller</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>997454464</td>\n",
       "      <td>Pi (1998)</td>\n",
       "      <td>Sci-Fi|Thriller</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>997454464</td>\n",
       "      <td>As Good As It Gets (1997)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>997454486</td>\n",
       "      <td>Crimson Tide (1995)</td>\n",
       "      <td>Drama|Thriller|War</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating       time                           title  \\\n",
       "0             1     3186       4  978300019        Girl, Interrupted (1999)   \n",
       "1             1     1270       5  978300055       Back to the Future (1985)   \n",
       "2             1     1721       4  978300055                  Titanic (1997)   \n",
       "3             1     1022       5  978300055               Cinderella (1950)   \n",
       "4             1     2340       3  978300103           Meet Joe Black (1998)   \n",
       "...         ...      ...     ...        ...                             ...   \n",
       "1000204    6040     2917       4  997454429                Body Heat (1981)   \n",
       "1000205    6040     1921       4  997454464                       Pi (1998)   \n",
       "1000206    6040     1784       3  997454464       As Good As It Gets (1997)   \n",
       "1000207    6040      161       3  997454486             Crimson Tide (1995)   \n",
       "1000208    6040     1221       4  998315055  Godfather: Part II, The (1974)   \n",
       "\n",
       "                               genres gender  age  occupation zipcode  \n",
       "0                               Drama      F    1          10   48067  \n",
       "1                       Comedy|Sci-Fi      F    1          10   48067  \n",
       "2                       Drama|Romance      F    1          10   48067  \n",
       "3        Animation|Children's|Musical      F    1          10   48067  \n",
       "4                             Romance      F    1          10   48067  \n",
       "...                               ...    ...  ...         ...     ...  \n",
       "1000204                Crime|Thriller      M   25           6   11106  \n",
       "1000205               Sci-Fi|Thriller      M   25           6   11106  \n",
       "1000206                  Comedy|Drama      M   25           6   11106  \n",
       "1000207            Drama|Thriller|War      M   25           6   11106  \n",
       "1000208            Action|Crime|Drama      M   25           6   11106  \n",
       "\n",
       "[1000209 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT_FOLDER = \"../datasets/factorization_machine/ml-1m/\"\n",
    "df_movies = pd.read_csv(DATA_ROOT_FOLDER+'movies.dat', sep='::',\n",
    "                        names=['movieId', 'title','genres'],\n",
    "                        encoding='latin-1',\n",
    "                        engine='python')\n",
    "\n",
    "user_cols = ['userId', 'gender' ,'age', 'occupation', 'zipcode']\n",
    "df_users = pd.read_csv(DATA_ROOT_FOLDER+'users.dat', sep='::',\n",
    "                       header=None,\n",
    "                       names=user_cols,\n",
    "                       engine='python')\n",
    "\n",
    "df = pd.read_csv(DATA_ROOT_FOLDER+'ratings.dat', sep='::',\n",
    "                 names=['userId','movieId','rating','time'],\n",
    "                 engine='python')\n",
    "# Left merge removes movies with no rating. # of unique movies: 3883 -> 3706\n",
    "df = df.merge(df_movies, on='movieId', how='left')\n",
    "df = df.merge(df_users, on='userId', how='left')\n",
    "df = df.sort_values(['userId', 'time'], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb325423-305c-48e5-9644-e61cc7ba1fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique userId: 6040\n",
      "# unique movieId: 3706\n",
      "# unique gender: 2\n",
      "# unique age: 7\n",
      "# unique occupation: 21\n",
      "Min # of ratings per user: 20\n",
      "Min/Max rating: 1 / 5\n",
      "df.shape: (1000209, 15)\n"
     ]
    }
   ],
   "source": [
    "encoder_dictionary = {}\n",
    "for cat_col in ['userId', 'movieId', 'gender', 'age', 'occupation']:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df[cat_col].unique())\n",
    "    df[cat_col+\"_index\"] = encoder.transform(df[cat_col])\n",
    "    encoder_dictionary[cat_col] = encoder\n",
    "    print(f'# unique {cat_col}: {len(encoder.classes_)}')\n",
    "\n",
    "\n",
    "min_num_ratings = df.groupby(['userId'])['userId'].transform(len).min()\n",
    "print(f'Min # of ratings per user: {min_num_ratings}')\n",
    "print(f'Min/Max rating: {df.rating.min()} / {df.rating.max()}')\n",
    "print(f'df.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6caee038-09ad-423c-b58f-f8a8bea373c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset - feature\n",
      "0      - userId_index\n",
      "6040   - movieId_index\n",
      "9746   - gender_index\n",
      "9748   - age_index\n",
      "9755   - occupation_index\n"
     ]
    }
   ],
   "source": [
    "# To use 1 embedding matrix, need to calculate & add offsets to each feature column\n",
    "# Orig. paper uses 1-hot encoding, here we use ordinal encoding\n",
    "# Ordinal encoding reduces memory size. Important for train speed\n",
    "feature_cols = ['userId_index', 'movieId_index', 'gender_index', 'age_index',\n",
    "                'occupation_index']\n",
    "# Get offsets\n",
    "feature_sizes = {}\n",
    "for feat in feature_cols:\n",
    "    feature_sizes[feat] = len(df[feat].unique())\n",
    "feature_offsets = {}\n",
    "NEXT_OFFSET = 0\n",
    "for k,v in feature_sizes.items():\n",
    "    feature_offsets[k] = NEXT_OFFSET\n",
    "    NEXT_OFFSET += v\n",
    "\n",
    "# Add offsets to each feature column\n",
    "for col in feature_cols:\n",
    "    df[col] = df[col].apply(lambda x: x + feature_offsets[col])\n",
    "print('Offset - feature')\n",
    "for k, os in feature_offsets.items():\n",
    "    print(f'{os:<6} - {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c991e6-a920-4460-b840-152e5aa704ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (90600, 6)\n",
      "df_val shape: (30200, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>userId_index</th>\n",
       "      <th>movieId_index</th>\n",
       "      <th>gender_index</th>\n",
       "      <th>age_index</th>\n",
       "      <th>occupation_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9009</td>\n",
       "      <td>9746</td>\n",
       "      <td>9748</td>\n",
       "      <td>9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7218</td>\n",
       "      <td>9746</td>\n",
       "      <td>9748</td>\n",
       "      <td>9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7614</td>\n",
       "      <td>9746</td>\n",
       "      <td>9748</td>\n",
       "      <td>9765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  userId_index  movieId_index  gender_index  age_index  \\\n",
       "0       4             0           9009          9746       9748   \n",
       "1       5             0           7218          9746       9748   \n",
       "2       4             0           7614          9746       9748   \n",
       "\n",
       "   occupation_index  \n",
       "0              9765  \n",
       "1              9765  \n",
       "2              9765  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRES = 5\n",
    "cols = ['rating', *feature_cols]\n",
    "df_train = df[cols].groupby('userId_index').head(15).reset_index(drop=True)\n",
    "df_val = df[cols].groupby('userId_index').tail(THRES).reset_index(drop=True)\n",
    "print(f'df_train shape: {df_train.shape}')\n",
    "print(f'df_val shape: {df_val.shape}')\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830134f4-1925-4728-947d-fbbc53ed48ef",
   "metadata": {},
   "source": [
    "## Creating dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a005d9be-8ca9-4898-9a4f-870c9657993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataSet(Dataset):\n",
    "    def __init__(self, df, x_feats, y_feat):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.x_feats = df[x_feats].values\n",
    "        self.y_rating = df[y_feat].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_feats[idx], self.y_rating[idx]\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "ds_train = MovieDataSet(df_train, feature_cols, 'rating')\n",
    "ds_val = MovieDataSet(df_val, feature_cols, 'rating')\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb52838-c64b-4623-a11d-0dbafc3b7de0",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df15c889-40c5-479a-b27a-1e3d1664b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_val))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2605a-dbdf-4eb3-8fda-7d40ce4d1702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d66d2b94-d4d8-46ee-b118-e12c8309c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMModel(nn.Module):\n",
    "    def __init__(self, num_feats, emb_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(num_feats, emb_dim)\n",
    "        self.bias = nn.Parameter(torch.zeros(num_feats))\n",
    "        self.offset = nn.Parameter(torch.zeros(1))\n",
    "        nn.init.xavier_normal_(self.embeddings.weight.data)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_emb = self.embeddings(x) # (BATCH, feature_length, embeddings)\n",
    "        pow_of_sum = x_emb.sum(dim=1).pow(2) # (BATCH, embeddings)\n",
    "        sum_of_pow = x_emb.pow(2).sum(dim=1) # (BATCH, embeddings)\n",
    "        fm_out = (pow_of_sum - sum_of_pow).sum(1)*0.5\n",
    "        x_biases = self.bias[x].sum(1) # ?????\n",
    "        fm_out += x_biases + self.offset\n",
    "        return self.sigmoid_range(fm_out, low=0.5)\n",
    "    \n",
    "    def sigmoid_range(self, x, low=0, high=5.5):\n",
    "        \"\"\" Sigmoid function with range (low, high) \"\"\"\n",
    "        return torch.sigmoid(x) * (high-low) + low\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a79a009-b1c1-4a62-bc8b-ba17d67791e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "65599b97-ab54-4c8b-9ffd-8d75e875a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'lr': 0.001,\n",
    "    'num_epochs': 15,\n",
    "    'weight_decay': 0.01,\n",
    "}\n",
    "n_feats = int(pd.concat([df_train, df_val]).max().max())\n",
    "n_feats = n_feats + 1 # \"+ 1\" to account for 0 - indexing\n",
    "model = FMModel(n_feats, emb_dim=8)\n",
    "model.to(device)\n",
    "opt = optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b17fbd54-b00e-427a-afa0-dc4ce24e1362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.43, Val Loss: 1.24\n",
      "Epoch: 1, Train Loss: 1.07, Val Loss: 1.16\n",
      "Epoch: 2, Train Loss: 0.97, Val Loss: 1.10\n",
      "Epoch: 3, Train Loss: 0.91, Val Loss: 1.07\n",
      "Epoch: 4, Train Loss: 0.87, Val Loss: 1.06\n",
      "Epoch: 5, Train Loss: 0.84, Val Loss: 1.05\n",
      "Epoch: 6, Train Loss: 0.82, Val Loss: 1.05\n",
      "Epoch: 7, Train Loss: 0.81, Val Loss: 1.05\n",
      "Epoch: 8, Train Loss: 0.80, Val Loss: 1.05\n",
      "Epoch: 9, Train Loss: 0.79, Val Loss: 1.06\n",
      "Epoch: 10, Train Loss: 0.79, Val Loss: 1.06\n",
      "Epoch: 11, Train Loss: 0.78, Val Loss: 1.06\n",
      "Epoch: 12, Train Loss: 0.78, Val Loss: 1.06\n",
      "Epoch: 13, Train Loss: 0.78, Val Loss: 1.07\n",
      "Epoch: 14, Train Loss: 0.77, Val Loss: 1.07\n"
     ]
    }
   ],
   "source": [
    "epoch_train_losses, epoch_val_losses = [], []\n",
    "for i in range(CFG[\"num_epochs\"]):\n",
    "    train_losses, val_losses = [], []\n",
    "    model.train()\n",
    "    for xb, yb in dl_train:\n",
    "        xb, yb = xb.to(device), yb.to(device, dtype=torch.float)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb) # input, true\n",
    "        train_losses.append(loss.item())\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dl_val:\n",
    "            b, yb = xb.to(device), yb.to(device, dtype=torch.float)\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds,yb)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)    \n",
    "    epoch_train_losses.append(epoch_train_loss)\n",
    "    epoch_val_losses.append(epoch_val_loss)\n",
    "    s = (f'Epoch: {i}, Train Loss: {epoch_train_loss:0.2f}, '\n",
    "         f'Val Loss: {epoch_val_loss:0.2f}'\n",
    "        )\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f1046-2f08-4ea2-8d22-10f2dacbf1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
